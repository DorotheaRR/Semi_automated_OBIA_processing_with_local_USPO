{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=6> <b> Table of Contents </b> </font> </center> \n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=5> <h1>Define working environment</h1> </font> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are used to: \n",
    "- Import needed libraries\n",
    "- Set the environment variables for Python, Anaconda, GRASS GIS and R statistical computing \n",
    "- Define the [\"GRASSDATA\" folder](https://grass.osgeo.org/grass73/manuals/helptext.html), the name of \"location\" and \"mapset\" where you will to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "\n",
    "## Import library for temporary files creation \n",
    "import tempfile \n",
    "\n",
    "## Import Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "## Import Numpy library\n",
    "import numpy\n",
    "\n",
    "## Import Psycopg2 library (interection with postgres database)\n",
    "import psycopg2 as pg\n",
    "\n",
    "# Import Math library (usefull for rounding number, e.g.)\n",
    "import math\n",
    "\n",
    "## Import Subprocess + subprocess.call\n",
    "import subprocess\n",
    "from subprocess import call, Popen, PIPE, STDOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=3> <h3>Environment variables when working on Linux Mint</h3> </font> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set 'Python' and 'GRASS GIS' environment variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we set [the environment variables allowing to use of GRASS GIS](https://grass.osgeo.org/grass64/manuals/variables.html) inside this Jupyter notebook. Please change the directory path according to your own system configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define GRASS GIS environment variables for LINUX UBUNTU Mint 18.1 (Serena)\n",
    "# Check is environmental variables exists and create them (empty) if not exists.\n",
    "if not 'PYTHONPATH' in os.environ:\n",
    "    os.environ['PYTHONPATH']=''\n",
    "if not 'LD_LIBRARY_PATH' in os.environ:\n",
    "    os.environ['LD_LIBRARY_PATH']=''\n",
    "# Set environmental variables\n",
    "os.environ['GISBASE'] = '/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu'\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'bin')\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'script')\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'lib')\n",
    "#os.environ['PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'etc','python')\n",
    "os.environ['PYTHONPATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'etc','python')\n",
    "os.environ['PYTHONPATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'etc','python','grass')\n",
    "os.environ['PYTHONPATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'etc','python','grass','script')\n",
    "os.environ['PYTHONLIB'] = '/usr/lib/python2.7'\n",
    "os.environ['LD_LIBRARY_PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'lib')\n",
    "os.environ['GIS_LOCK'] = '$$'\n",
    "os.environ['GISRC'] = os.path.join(os.environ['HOME'],'.grass7','rc')\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['HOME'],'.grass7','addons')\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['HOME'],'.grass7','addons','bin')\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['HOME'],'.grass7','addons')\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['HOME'],'.grass7','addons','scripts')\n",
    "\n",
    "## Define GRASS-Python environment\n",
    "sys.path.append(os.path.join(os.environ['GISBASE'],'etc','python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Display current environment variables of your computer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDMSESSION = mate \t\n",
      "MANDATORY_PATH = /usr/share/gconf/mate.mandatory.path \t\n",
      "MATE_DESKTOP_SESSION_ID = this-is-deprecated \t\n",
      "LESSOPEN = | /usr/bin/lesspipe %s \t\n",
      "MDM_LANG = fr_BE.UTF-8 \t\n",
      "LOGNAME = tais \t\n",
      "USER = tais \t\n",
      "HOME = /home/tais \t\n",
      "XDG_VTNR = 8 \t\n",
      "PATH = /usr/local/bin:/home/tais/BIN:/home/tais/bin:/home/tais/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/bin:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/script:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/lib:/home/tais/.grass7/addons:/home/tais/.grass7/addons/bin:/home/tais/.grass7/addons:/home/tais/.grass7/addons/scripts \t\n",
      "CLICOLOR = 1 \t\n",
      "DISPLAY = :0.0 \t\n",
      "SSH_AGENT_PID = 2066 \t\n",
      "LANG = fr_BE.UTF-8 \t\n",
      "TERM = xterm-color \t\n",
      "SHELL = /bin/bash \t\n",
      "GIS_LOCK = $$ \t\n",
      "XAUTHORITY = /home/tais/.Xauthority \t\n",
      "SESSION_MANAGER = local/tais-HP-Z620-Workstation:@/tmp/.ICE-unix/1995,unix/tais-HP-Z620-Workstation:/tmp/.ICE-unix/1995 \t\n",
      "SHLVL = 1 \t\n",
      "QT_LINUX_ACCESSIBILITY_ALWAYS_ON = 1 \t\n",
      "INSIDE_CAJA_PYTHON =  \t\n",
      "QT_ACCESSIBILITY = 1 \t\n",
      "LD_LIBRARY_PATH = :/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/lib \t\n",
      "COMPIZ_CONFIG_PROFILE = mate \t\n",
      "WINDOWPATH = 8 \t\n",
      "GTK_OVERLAY_SCROLLING = 0 \t\n",
      "PYTHONPATH = :/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/etc/python:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/etc/python/grass:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/etc/python/grass/script \t\n",
      "GISBASE = /home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu \t\n",
      "CLUTTER_BACKEND = x11 \t\n",
      "USERNAME = tais \t\n",
      "XDG_SESSION_DESKTOP = mate \t\n",
      "GDM_XSERVER_LOCATION = local \t\n",
      "XDG_RUNTIME_DIR = /run/user/1000 \t\n",
      "JPY_PARENT_PID = 7298 \t\n",
      "QT_STYLE_OVERRIDE = gtk \t\n",
      "SSH_AUTH_SOCK = /run/user/1000/keyring/ssh \t\n",
      "VTE_VERSION = 4205 \t\n",
      "GDMSESSION = mate \t\n",
      "GISRC = /home/tais/.grass7/rc \t\n",
      "GIT_PAGER = cat \t\n",
      "XDG_CONFIG_DIRS = /etc/xdg/xdg-mate:/etc/xdg \t\n",
      "XDG_CURRENT_DESKTOP = MATE \t\n",
      "XDG_SESSION_ID = c1 \t\n",
      "DBUS_SESSION_BUS_ADDRESS = unix:abstract=/tmp/dbus-HQg01KxGx1,guid=5adb60f2fb9cb695876d89a05a25171e \t\n",
      "_ = /usr/local/bin/jupyter \t\n",
      "XDG_SESSION_COOKIE = 8441891e86e24d76b9616edf516d5734-1512380190.44057-252399727 \t\n",
      "DESKTOP_SESSION = mate \t\n",
      "WINDOWID = 54525958 \t\n",
      "LESSCLOSE = /usr/bin/lesspipe %s %s \t\n",
      "DEFAULTS_PATH = /usr/share/gconf/mate.default.path \t\n",
      "MPLBACKEND = module://ipykernel.pylab.backend_inline \t\n",
      "MDM_XSERVER_LOCATION = local \t\n",
      "GTK_MODULES = gail:atk-bridge \t\n",
      "XDG_DATA_DIRS = /usr/share/mate:/usr/local/share/:/usr/share/:/usr/share/mdm/ \t\n",
      "PWD = /media/tais/My_Book_1/MAUPP/Traitement/Ouagadougou/Segmentation_fullAOI_localapproach/Notebooks \t\n",
      "COLORTERM = mate-terminal \t\n",
      "PYTHONLIB = /usr/lib/python2.7 \t\n",
      "LS_COLORS = rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36: \t\n",
      "PAGER = cat \t\n",
      "XDG_SEAT = seat0 \t\n"
     ]
    }
   ],
   "source": [
    "## Display the current defined environment variables\n",
    "for key in os.environ.keys():\n",
    "    print \"%s = %s \\t\" % (key,os.environ[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=5> <h1>User inputs</h1> </font> </center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define a empty dictionnary for saving user inputs\n",
    "user={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after:\n",
    "- Enter the path to the directory you want to use as \"[GRASSDATA](https://grass.osgeo.org/programming7/loc_struct.png)\". \n",
    "- Enter the name of the location in which you want to work and its projection information in [EPSG code](http://spatialreference.org/ref/epsg/) format. Please note that the GRASSDATA folder and locations will be automatically created if not existing yet. If the location name already exists, the projection information will not be used.  \n",
    "- Enter the name you want for the mapsets which will be used later for Unsupervised Segmentation Parameter Optimization (USPO), Segmentation and Classification steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter the path to GRASSDATA folder\n",
    "user[\"gisdb\"] = \"/media/tais/My_Book_1/MAUPP/Traitement/Ouagadougou/Segmentation_fullAOI_localapproach/GRASSDATA\"\n",
    "\n",
    "## Enter the name of the location (existing or for a new one)\n",
    "user[\"location\"] = \"Ouaga_32630\"\n",
    "\n",
    "## Enter the EPSG code for this location \n",
    "user[\"locationepsg\"] = \"32630\"\n",
    "\n",
    "## Enter the name of the mapset to use for segmentation\n",
    "user[\"segmentation_mapsetname\"] = \"LOCAL_SEGMENT\"\n",
    "\n",
    "## Enter the name of the mapset to use for classification\n",
    "user[\"classificationA_mapsetname\"] = \"CLASSIF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=5> <h1>Define GRASSDATA folder and create GRASS' location and mapsets</h1> </font> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, the python script will check if GRASSDATA folder, locations and mapsets already exist. If not, they will be automatically created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Import GRASS Python packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "\n",
    "## Import libraries needed to call GRASS using Python\n",
    "import grass.script as grass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Define GRASSDATA folder and create location and mapsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRASSDATA folder already exist\n"
     ]
    }
   ],
   "source": [
    "## Automatic creation of GRASSDATA folder\n",
    "if os.path.exists(user[\"gisdb\"]):\n",
    "    print \"GRASSDATA folder already exist\" \n",
    "else: \n",
    "    os.makedirs(user[\"gisdb\"]) \n",
    "    print \"GRASSDATA folder created in \"+user[\"gisdb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Ouaga_32630 already exist\n"
     ]
    }
   ],
   "source": [
    "## Automatic creation of GRASS location is doesn't exist\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"])):\n",
    "    print \"Location \"+user[\"location\"]+\" already exist\" \n",
    "else : \n",
    "    grass.core.create_location(user[\"gisdb\"], user[\"location\"], epsg=user[\"locationepsg\"], overwrite=False)\n",
    "    print \"Location \"+user[\"location\"]+\" created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CLASSIF' mapset already exist\n"
     ]
    }
   ],
   "source": [
    "### Automatic creation of GRASS GIS mapsets\n",
    "\n",
    "## Import library for file copying \n",
    "import shutil\n",
    "\n",
    "mapsetname=user[\"classificationA_mapsetname\"]\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname)):\n",
    "    if not os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname,'WIND')):\n",
    "        print \"WARNING: '\"+mapsetname+\"' mapset already exist, but a 'WIND' file is missing. Please solve this issue.\"\n",
    "    else: print \"'\"+mapsetname+\"' mapset already exist\" \n",
    "else: \n",
    "    os.makedirs(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname))\n",
    "    shutil.copy(os.path.join(user[\"gisdb\"],user[\"location\"],'PERMANENT','WIND'),os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname,'WIND'))\n",
    "    print \"'\"+mapsetname+\"' mapset created in location '\"+user[\"location\"]+\"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LOCAL_SEGMENT' mapset already exist\n"
     ]
    }
   ],
   "source": [
    "### Automatic creation of GRASS GIS mapsets\n",
    "\n",
    "## Import library for file copying \n",
    "import shutil\n",
    "\n",
    "mapsetname=user[\"segmentation_mapsetname\"]\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname)):\n",
    "    if not os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname,'WIND')):\n",
    "        print \"WARNING: '\"+mapsetname+\"' mapset already exist, but a 'WIND' file is missing. Please solve this issue.\"\n",
    "    else: print \"'\"+mapsetname+\"' mapset already exist\" \n",
    "else: \n",
    "    os.makedirs(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname))\n",
    "    shutil.copy(os.path.join(user[\"gisdb\"],user[\"location\"],'PERMANENT','WIND'),os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname,'WIND'))\n",
    "    print \"'\"+mapsetname+\"' mapset created in location '\"+user[\"location\"]+\"'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=5> <h1>Define functions</h1> </font> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook is dedicated to defining functions which will then be called later in the script. If you want to create your own functions, define them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing processing time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"print_processing_time\" is used to calculate and display the processing time for various stages of the processing chain. At the beginning of each major step, the current time is stored in a new variable, using [time.time() function](https://docs.python.org/2/library/time.html). At the end of the stage in question, the \"print_processing_time\" function is called and takes as argument the name of this new variable containing the recorded time at the beginning of the stage, and an output message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import library for managing time in python\n",
    "import time  \n",
    "\n",
    "## Function \"print_processing_time()\" compute processing time and printing it.\n",
    "# The argument \"begintime\" wait for a variable containing the begintime (result of time.time()) of the process for which to compute processing time.\n",
    "# The argument \"printmessage\" wait for a string format with information about the process. \n",
    "def print_processing_time(begintime, printmessage):    \n",
    "    endtime=time.time()           \n",
    "    processtime=endtime-begintime\n",
    "    remainingtime=processtime\n",
    "\n",
    "    days=int((remainingtime)/86400)\n",
    "    remainingtime-=(days*86400)\n",
    "    hours=int((remainingtime)/3600)\n",
    "    remainingtime-=(hours*3600)\n",
    "    minutes=int((remainingtime)/60)\n",
    "    remainingtime-=(minutes*60)\n",
    "    seconds=round((remainingtime)%60,1)\n",
    "\n",
    "    if processtime<60:\n",
    "        finalprintmessage=str(printmessage)+str(seconds)+\" seconds\"\n",
    "    elif processtime<3600:\n",
    "        finalprintmessage=str(printmessage)+str(minutes)+\" minutes and \"+str(seconds)+\" seconds\"\n",
    "    elif processtime<86400:\n",
    "        finalprintmessage=str(printmessage)+str(hours)+\" hours and \"+str(minutes)+\" minutes and \"+str(seconds)+\" seconds\"\n",
    "    elif processtime>=86400:\n",
    "        finalprintmessage=str(printmessage)+str(days)+\" days, \"+str(hours)+\" hours and \"+str(minutes)+\" minutes and \"+str(seconds)+\" seconds\"\n",
    "    \n",
    "    return finalprintmessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Function for Postgres database vaccum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do a VACUUM on the current Postgresql database\n",
    "def vacuum(db):\n",
    "    old_isolation_level = db.isolation_level\n",
    "    db.set_isolation_level(0)\n",
    "    query = \"VACUUM\"\n",
    "    cur.execute(query)\n",
    "    db.set_isolation_level(old_isolation_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_full=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameter for Postgresql database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User for postgresql connexion\n",
    "dbuser=\"tais\"\n",
    "# Password of user\n",
    "dbpassword=\"tais\"\n",
    "# Host of database\n",
    "host=\"localhost\"\n",
    "# Name of the new database\n",
    "dbname=\"ouaga_fullaoi_localsegment\"\n",
    "# Set name of schema for objects statistics\n",
    "stat_schema=\"statistics\"\n",
    "# Set name of schema for samples\n",
    "sample_schema=\"samples\"\n",
    "# Set name of table with statistics of segmentobject_stats_table=\"object_stats_sar\"s - FOR OPTICAL\n",
    "object_stats_optical=\"object_stats_optical\"\n",
    "# Set name of table with statistics of segmentobject_stats_table=\"object_stats_sar\"s - FOR SAR\n",
    "object_stats_sar=\"object_stats_sar\"\n",
    "# Set name of table with all the samples\n",
    "samples_labels=\"sample_labels\"\n",
    "# Set name of table with samples without outliers\n",
    "samples_labels_ok=\"sample_labels_ok\"\n",
    "# Set name of table with samples without outliers in Optical AOI\n",
    "sample_opt=\"sample_opt\"\n",
    "# Set name of table with samples without outliers in Optical AOI - Test set\n",
    "sample_opt_test=\"sample_opt_test\"\n",
    "# Set name of table with samples without outliers in Optical AOI - Training set\n",
    "sample_opt_training=\"sample_opt_training\"\n",
    "# Set name of table with samples without outliers in SAR AOI\n",
    "sample_sar=\"sample_sar\"\n",
    "# Set name of table with samples without outliers in SAR AOI - Test set\n",
    "sample_test=\"sample_test\"\n",
    "# Set name of table with samples without outliers in SAR AOI - Training set\n",
    "sample_training=\"sample_training\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=5> <h1>Select samples in segmentation layer</h1> </font>  </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Launch GRASS GIS working session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now working in mapset 'CLASSIF'\n"
     ]
    }
   ],
   "source": [
    "## Set the name of the mapset in which to work\n",
    "mapsetname=user[\"classificationA_mapsetname\"]\n",
    "\n",
    "## Launch GRASS GIS working session in the mapset\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname)):\n",
    "    gsetup.init(os.environ['GISBASE'], user[\"gisdb\"], user[\"location\"], mapsetname)\n",
    "    print \"You are now working in mapset '\"+mapsetname+\"'\" \n",
    "else: \n",
    "    print \"'\"+mapsetname+\"' mapset doesn't exists in \"+user[\"gisdb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create new schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occured : ERREUR:  le schéma « statistics » existe déjà\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# Connect to postgres database\n",
    "db=None\n",
    "db=pg.connect(dbname=dbname, user='tais', password='tais', host='localhost')\n",
    "\n",
    "# Allow to create a new database\n",
    "db.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "\n",
    "# Execute the CREATE DATABASE query\n",
    "cur=db.cursor()\n",
    "#cur.execute('DROP SCHEMA IF EXISTS '+schema+' CASCADE') #Comment this to avoid deleting existing DB\n",
    "try:\n",
    "    cur.execute('CREATE SCHEMA '+stat_schema)\n",
    "except Exception as e:\n",
    "    print (\"Exception occured : \"+str(e))\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the folder where to save the results and create it if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, please adapt the path to the directory where you want to save the .csv output of i.segment.uspo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Folder in which save processing time output\n",
    "resultfolder=\"/media/tais/My_Book_1/MAUPP/Traitement/Ouagadougou/Segmentation_fullAOI_localapproach/Results/CLASSIF/samples\"\n",
    "\n",
    "## Create the folder if does not exists\n",
    "if not os.path.exists(resultfolder):\n",
    "    os.makedirs(resultfolder)\n",
    "    print \"Folder '\"+resultfolder+\"' created\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import sample points in a vector layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Set the path to the .shp file with validation samples\n",
    "pathtovalidationsampleshp=\"/media/tais/data/MAUPP/WorldView3_Ouagadougou/Training_validation/Densification/Densified_samples_SPIE2017.shp\"\n",
    "\n",
    "## Set the path to the .shp file with training samples\n",
    "pathtotrainingsampleshp=\"/media/tais/data/MAUPP/Articles/SPIE_RemoteSensing2017/Grippa/Data/samples_training.shp\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Set computational region to match the default region\n",
    "grass.run_command('g.region', overwrite=True, raster=\"segments\")\n",
    "\n",
    "## Import validation sample data (points)\n",
    "grass.run_command('v.in.ogr', overwrite=True, input=pathtovalidationsampleshp, output='samples_validation')\n",
    "    \n",
    "## Import training sample data (points)\n",
    "grass.run_command('v.in.ogr', overwrite=True, input=pathtotrainingsampleshp, output='samples_training')\n",
    "    \n",
    "## Print\n",
    "print \"Point sample imported on \"+time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set the path to the .shp file with training/test samples\n",
    "pathtosampleshp=\"/media/tais/data/MAUPP/WorldView3_Ouagadougou/Training_validation/Final_sample_ouaga/Ouagadougou_fullextend_sample.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point sample imported on Thu Nov 30 11:17:49 2017\n"
     ]
    }
   ],
   "source": [
    "## Set computational region to match the default region\n",
    "grass.run_command('g.region', overwrite=True, raster=\"segments\")\n",
    "\n",
    "## Import training/test sample data (points)\n",
    "grass.run_command('v.in.ogr', overwrite=True, input=pathtosampleshp, output='samples')\n",
    "    \n",
    "## Print\n",
    "print \"Point sample imported on \"+time.ctime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify which segment correspond to each point (for both validation and training) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our processing chain, the training and test sets are formed of points. However, objects are needed to train the supervised classification in OBIA context. In this section, each point in the training set is used to identify the underlying object in the segmentation layer, and save its unique ID. We use the ['v.db.addcolumn' command](https://grass.osgeo.org/grass72/manuals/v.db.addcolumn.html), ['v.what.rast' command](https://grass.osgeo.org/grass72/manuals/v.what.rast.html) for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Segment iD added in attribute table in 3.6 seconds'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_whatrast=time.time()\n",
    "## Add a column \"seg_id\" in training_set layer\n",
    "grass.run_command('v.db.addcolumn', map=\"samples\", columns=\"seg_id int\")\n",
    "## Set computational region to the default region\n",
    "grass.run_command('g.region', raster=\"segments\")\n",
    "## For each training point, add the value of the underlying segmentation raster pixel in column \"seg_id\"\n",
    "grass.run_command('v.what.rast', map=\"samples\", raster=\"segments\", column=\"seg_id\")\n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_whatrast, \"Segment iD added in attribute table in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute table exported on '/tmp/tempfile_samples.csv' file\n"
     ]
    }
   ],
   "source": [
    "# Create temporary file for work\n",
    "tmpfile_sample=os.path.join(tempfile.gettempdir(),\"tempfile_samples.csv\")\n",
    "# Export the attribute of the 'samples' layer\n",
    "grass.run_command('db.out.ogr', overwrite=True, input='samples', output=tmpfile_sample, format='CSV')\n",
    "# Print what happened\n",
    "print \"Attribute table exported on '\"+tmpfile_sample+\"' file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import samples in a new postgresql table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(database=dbname, user=dbuser, password=dbpassword, host=host)\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+sample_schema+\".\"+samples_labels)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define which tmpfile to use (validation or training)\n",
    "tmpfile=tmpfile_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a new table 'samples.sample_labels' with header corresponding to the first row of file '/tmp/tempfile_samples.csv'\n",
      "CREATE TABLE samples.sample_labels (cat_point integer PRIMARY KEY, id text, code text, code_roof text, class text, osm text, class_num text, roof_num text, seg_id integer)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# Create a empty list for saving of column name\n",
    "column_name=[]\n",
    "# Create a reader for the first csv file in the stack of csv to be imported\n",
    "readercsvSubset=open(tmpfile)\n",
    "readercsv=csv.reader(readercsvSubset, delimiter=',') \n",
    "headerline=readercsv.next()\n",
    "print \"Create a new table '\"+sample_schema+\".\"+samples_labels+\"' with header corresponding to the first row of file '\"+tmpfile+\"'\"\n",
    "\n",
    "## Build a query for creation of a new table with auto-incremental key-value (thus avoiding potential duplicates of 'cat' value)\n",
    "# All column data-types are set to 'text' in order to be able to import some 'nan', 'inf' or 'null' values present in statistics files\n",
    "# This table will allow to import all individual csv files in a single Postgres table, which will be cleaned after\n",
    "query=\"CREATE TABLE \"+sample_schema+\".\"+samples_labels+\" (\"\n",
    "query+=str(headerline[0])+\"_point\"+\" integer PRIMARY KEY\"\n",
    "for column in headerline[1:]:\n",
    "    if column in ('id','osm','class_num','roof_num','seg_id'):\n",
    "        query+=\",\"\n",
    "        query+=\" \"+str(column)+\" integer\"\n",
    "    else:\n",
    "        query+=\",\"\n",
    "        query+=\" \"+str(column)+\" text\"\n",
    "query+=\")\"\n",
    "\n",
    "# Close the current input file\n",
    "readercsvSubset.close()\n",
    "    \n",
    "# Print the query\n",
    "print query\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy from .csv in postgresql table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start copy csv file in the postgresql table\n",
      "Process achieved in 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_copy=time.time()\n",
    "\n",
    "## Print\n",
    "print \"Start copy csv file in the postgresql table\"\n",
    "\n",
    "# Create query for copy data from csv, avoiding the header\n",
    "query=\"COPY \"+sample_schema+\".\"+samples_labels+\" \\\n",
    "FROM '\"+str(tmpfile)+\"' HEADER DELIMITER ',' CSV;\" \n",
    "# Execute the COPY FROM CSV query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()    \n",
    "\n",
    "## Compute processing time and print it\n",
    "print print_processing_time(begintime_copy, \"Process achieved in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buildings</td>\n",
       "      <td>11</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buildings under construction</td>\n",
       "      <td>12</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Swimming pools</td>\n",
       "      <td>13</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asphalt surfaces</td>\n",
       "      <td>14</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brown/red bare soil</td>\n",
       "      <td>21</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>White/grey bare soil</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trees</td>\n",
       "      <td>31</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mixed bare soil/vegetation</td>\n",
       "      <td>32</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dry vegetation</td>\n",
       "      <td>33</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Other vegetation</td>\n",
       "      <td>34</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inland waters</td>\n",
       "      <td>41</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shadows</td>\n",
       "      <td>51</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           class class_num  count\n",
       "0                      Buildings        11    429\n",
       "1   Buildings under construction        12    123\n",
       "2                 Swimming pools        13    183\n",
       "3               Asphalt surfaces        14    242\n",
       "4            Brown/red bare soil        21    216\n",
       "5           White/grey bare soil        22    200\n",
       "6                          Trees        31    217\n",
       "7     Mixed bare soil/vegetation        32    225\n",
       "8                 Dry vegetation        33    191\n",
       "9               Other vegetation        34    322\n",
       "10                 Inland waters        41    223\n",
       "11                       Shadows        51    191"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to find the number of row in the sample table\n",
    "query=\"SELECT class, max(class_num) as class_num, count(*) FROM \"+sample_schema+\".\"+samples_labels+\" \\\n",
    "GROUP BY class \\\n",
    "ORDER BY max(class_num) ASC\"\n",
    "# Execute query through panda\n",
    "df=pd.read_sql(query, db)\n",
    "# Show dataframe\n",
    "df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample counts 2762 points.\n"
     ]
    }
   ],
   "source": [
    "# Print the total number in sample \n",
    "print \"Original sample counts \"+str(sum(df['count']))+\" points.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated segments which will be remove from samples\n"
     ]
    }
   ],
   "source": [
    "# Query to find 'seg_id' wich are duplicated in the sample\n",
    "query=\"SELECT seg_id FROM \"+sample_schema+\".\"+samples_labels+\" \\\n",
    "GROUP BY seg_id HAVING count(*) > 1.0\"\n",
    "# Execute query through panda\n",
    "df=pd.read_sql(query, db)\n",
    "duplicated_segid=list(df['seg_id'])\n",
    "print \"There are \"+str(len(duplicated_segid))+\" duplicated segments which will be remove from samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Remove rejected segments from the 'sample_stat' table\n",
    "# Query\n",
    "query=\"DELETE FROM \"+sample_schema+\".\"+samples_labels+\" \\\n",
    "WHERE seg_id IN ('\"+\"','\".join([str(x) for x in duplicated_segid])+\"')\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vacuum the current Postgresql database\n",
    "vacuum(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers from the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(database=dbname, user=dbuser, password=dbpassword, host=host)\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Notice about the visual interpretation of outlier segments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "95% of segments where visually assessed using the results of local segmentation parameter optimization approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save a list with 'seg_id' to be removed\n",
    "remove_list=[6255402,7744776,7044799,6078235,10502897,6876381,12300768,6247378,12499295,6329556,6482113,\n",
    "             3875007,12515665,2980639,7408144,2994968,12588869,7254663,2720755,7945387,6928527,7328013,\n",
    "             2227885,2557822,2123292,8299882,15173102,2882248,6829153,6999865,14445665,15096549,12415122,\n",
    "             15097739,9716573,7142033,5181162,1111646,2840051,2871072,8619751,4647146,15087616,4451966,3028339,\n",
    "             15408522,14671220,7713534,4577021,15003423,7878206,3526056,13818795,1538896,3531654,13463235,\n",
    "             6691796,2008255,5486015,1706531,6090721,10120225,4950334,9911243,7554597,8397760,8166828,\n",
    "             8754793,4034215,11982782,8301269,7720700,5766862,6334137,5602235,10336548,7857639,8807988,6927462,\n",
    "             11373495,2652049,12423996,14781702,5410572,2640910,6289370,15339998,90558,2158038,5694526,1861549,\n",
    "             9308271,6608980,1100126,1547484,1512319,11273219,965059,321422,12428549,8391892,1890247,6161203,\n",
    "             1947701,5077535,1844748,6261486,1763602,5410108,2956301,7473524,3414099,5366216,3977046,870198,\n",
    "             7872932,3341959,5366949,2170072,6930780,2181069,2053367,6233224,6507816,6550503,7731307,3563944,\n",
    "             4738499,3373619,3373619,3676702,10714804,3912663,5050862,3737696,11249864,2126825,12870533,6906431,\n",
    "             3402173,1665297,2285263,1512731,3106970,9051990,11383089,7764629,6791455,6677946,4705013,10720407,\n",
    "             7833880,7260635,6515879,7041313,7618921,8010467,7982801,7227661,5001150,7186494,7280282,2684001,\n",
    "             10513768,6271320,10913026,3253125,10483233,1800856,11894344,1707528,6883962,7002283,11860118,6859894]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create and update a 'remove' column base on a list of seg_id to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add column for prediction at level 2 + label of level 2 classes\n",
    "query=\"ALTER TABLE \"+sample_schema+\".\"+samples_labels+\" ADD COLUMN remove text\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the 'remove' column with 'yes'\n",
    "query=\"UPDATE \"+sample_schema+\".\"+samples_labels+\" \\\n",
    "SET remove = 'yes' WHERE  seg_id IN (\"+\",\".join(str(x) for x in remove_list)+\")\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Update the 'remove' column with 'no'\n",
    "query=\"UPDATE \"+sample_schema+\".\"+samples_labels+\" \\\n",
    "SET remove = 'no' WHERE  seg_id NOT IN (\"+\",\".join(str(x) for x in remove_list)+\")\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create new table with sample which are not outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+sample_schema+\".\"+samples_labels_ok)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the 'remove' column with 'yes'\n",
    "query=\"CREATE TABLE \"+sample_schema+\".\"+samples_labels_ok+\" AS(\\\n",
    "SELECT * FROM \"+sample_schema+\".\"+samples_labels+\" WHERE remove = 'no')\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test sample for SAR aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create new table with sample which are not outliers and included in SAR AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+sample_schema+\".\"+sample_sar)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the 'remove' column with 'yes'\n",
    "query=\"CREATE TABLE \"+sample_schema+\".\"+sample_sar+\" AS(\\\n",
    "SELECT a.* FROM \"+sample_schema+\".\"+samples_labels_ok+\" AS a \\\n",
    "INNER JOIN \"+stat_schema+\".\"+object_stats_sar+\" AS b \\\n",
    "ON a.seg_id=b.cat)\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Delete samples whose class is 12 (building under construction) or 51 (Shadows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the 'remove' column with 'yes'\n",
    "query=\"DELETE FROM \"+sample_schema+\".\"+sample_sar+\" \\\n",
    "WHERE class_num = '12' OR class_num = '51'\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check if size of sample is sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buildings</td>\n",
       "      <td>11</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swimming pools</td>\n",
       "      <td>13</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asphalt surfaces</td>\n",
       "      <td>14</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown/red bare soil</td>\n",
       "      <td>21</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White/grey bare soil</td>\n",
       "      <td>22</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trees</td>\n",
       "      <td>31</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mixed bare soil/vegetation</td>\n",
       "      <td>32</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dry vegetation</td>\n",
       "      <td>33</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other vegetation</td>\n",
       "      <td>34</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Inland waters</td>\n",
       "      <td>41</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        class class_num  count\n",
       "0                   Buildings        11    402\n",
       "1              Swimming pools        13    167\n",
       "2            Asphalt surfaces        14    139\n",
       "3         Brown/red bare soil        21    196\n",
       "4        White/grey bare soil        22    162\n",
       "5                       Trees        31    186\n",
       "6  Mixed bare soil/vegetation        32    193\n",
       "7              Dry vegetation        33    171\n",
       "8            Other vegetation        34    300\n",
       "9               Inland waters        41    188"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to find the number of row in the sample table\n",
    "query=\"SELECT class, min(class_num) as class_num, count(*) FROM \"+sample_schema+\".\"+sample_sar+\" \\\n",
    "GROUP BY class \\\n",
    "ORDER BY max(class_num) ASC\"\n",
    "# Execute query through panda\n",
    "df_countperclass=pd.read_sql(query, db)\n",
    "# Show dataframe\n",
    "df_countperclass.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtred sample counts 2104 points.\n"
     ]
    }
   ],
   "source": [
    "# Print the total number in sample \n",
    "print \"Filtred sample counts \"+str(sum(df_countperclass['count']))+\" points.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the sample is sufficient\n"
     ]
    }
   ],
   "source": [
    "## Set the minimum size of sample for each class\n",
    "minimumsize=60\n",
    "## Check for each class if the number of sample at least equals the minimum size\n",
    "checkvariable=0\n",
    "for row in range(0,len(df_countperclass.index)):\n",
    "    if int(df_countperclass.loc[row,['count']])<minimumsize:\n",
    "        checkvariable+=1\n",
    "        print \"WARNING: The minimum number of sample is not respected for class '\"+list(df_countperclass.loc[row,['class']])[0]+\"'\"\n",
    "if checkvariable<=0:\n",
    "        print \"The size of the sample is sufficient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vacuum the current Postgresql database\n",
    "vacuum(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random selection of test set and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(database=dbname, user=dbuser, password=dbpassword, host=host)\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 distinct classes are 11,13,14,21,22,31,32,33,34,41\n"
     ]
    }
   ],
   "source": [
    "## Create a list with distinct values of class\n",
    "class_column=\"class_num\"\n",
    "query=\"SELECT DISTINCT \"+class_column+\" AS distinct_class from \"+sample_schema+\".\"+sample_sar\n",
    "# Execute query through panda\n",
    "df=pd.read_sql(query, db)\n",
    "# Save estimated number of objects\n",
    "class_list=list(df['distinct_class'])\n",
    "# Print\n",
    "print str(len(class_list))+\" distinct classes are \"+\",\".join([str(y) for y in sorted([int(x) for x in class_list])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 samples will be selected for test\n"
     ]
    }
   ],
   "source": [
    "## Loop on the class_list and save cat_point in a list\n",
    "number_test_perclass=40\n",
    "testsample_list=[]\n",
    "for distinct_class in class_list:\n",
    "    query=\"SELECT cat_point FROM \"+sample_schema+\".\"+sample_sar+\" WHERE random() < 0.5 \\\n",
    "    AND \"+class_column+\"='\"+distinct_class+\"'\\\n",
    "    ORDER BY random() LIMIT 40\"\n",
    "    # Execute query through panda\n",
    "    df=pd.read_sql(query, db)\n",
    "    # Save estimated number of objects\n",
    "    for x in list(df['cat_point']):\n",
    "        testsample_list.append(str(x))\n",
    "    \n",
    "# Print\n",
    "print str(len(testsample_list))+\" samples will be selected for test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+sample_schema+\".\"+sample_test)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Subquery\n",
    "subquery1=\"SELECT * FROM \"+sample_schema+\".\"+sample_sar+\" \\\n",
    "WHERE cat_point IN (\"+\",\".join(testsample_list)+\")\"\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+sample_schema+\".\"+sample_test+\" AS(\"+subquery1+\")\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buildings</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swimming pools</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asphalt surfaces</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown/red bare soil</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White/grey bare soil</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trees</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mixed bare soil/vegetation</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dry vegetation</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other vegetation</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Inland waters</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        class class_num  count\n",
       "0                   Buildings        11     40\n",
       "1              Swimming pools        13     40\n",
       "2            Asphalt surfaces        14     40\n",
       "3         Brown/red bare soil        21     40\n",
       "4        White/grey bare soil        22     40\n",
       "5                       Trees        31     40\n",
       "6  Mixed bare soil/vegetation        32     40\n",
       "7              Dry vegetation        33     40\n",
       "8            Other vegetation        34     40\n",
       "9               Inland waters        41     40"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to find the number of row in the test samples\n",
    "query=\"SELECT class, min(class_num) as class_num, count(*) FROM \"+sample_schema+\".\"+sample_test+\" \\\n",
    "GROUP BY class \\\n",
    "ORDER BY max(class_num) ASC\"\n",
    "# Execute query through panda\n",
    "df_countperclass=pd.read_sql(query, db)\n",
    "# Show dataframe\n",
    "df_countperclass.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples counts 400 points.\n"
     ]
    }
   ],
   "source": [
    "# Print the total number in sample \n",
    "print \"Test samples counts \"+str(sum(df_countperclass['count']))+\" points.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select training samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+sample_schema+\".\"+sample_training)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Subquery\n",
    "subquery1=\"SELECT * FROM \"+sample_schema+\".\"+sample_sar+\" \\\n",
    "WHERE cat_point NOT IN (\"+\",\".join(testsample_list)+\")\"\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+sample_schema+\".\"+sample_training+\" AS(\"+subquery1+\")\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buildings</td>\n",
       "      <td>11</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swimming pools</td>\n",
       "      <td>13</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asphalt surfaces</td>\n",
       "      <td>14</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown/red bare soil</td>\n",
       "      <td>21</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White/grey bare soil</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trees</td>\n",
       "      <td>31</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mixed bare soil/vegetation</td>\n",
       "      <td>32</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dry vegetation</td>\n",
       "      <td>33</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other vegetation</td>\n",
       "      <td>34</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Inland waters</td>\n",
       "      <td>41</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        class class_num  count\n",
       "0                   Buildings        11    362\n",
       "1              Swimming pools        13    127\n",
       "2            Asphalt surfaces        14     99\n",
       "3         Brown/red bare soil        21    156\n",
       "4        White/grey bare soil        22    122\n",
       "5                       Trees        31    146\n",
       "6  Mixed bare soil/vegetation        32    153\n",
       "7              Dry vegetation        33    131\n",
       "8            Other vegetation        34    260\n",
       "9               Inland waters        41    148"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to find the number of row in the sample table\n",
    "query=\"SELECT class, min(class_num) as class_num, count(*) FROM \"+sample_schema+\".\"+sample_training+\" \\\n",
    "GROUP BY class \\\n",
    "ORDER BY max(class_num) ASC\"\n",
    "# Execute query through panda\n",
    "df_countperclass=pd.read_sql(query, db)\n",
    "# Show dataframe\n",
    "df_countperclass.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples counts 1704 points.\n"
     ]
    }
   ],
   "source": [
    "# Print the total number in sample \n",
    "print \"Training samples counts \"+str(sum(df_countperclass['count']))+\" points.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export full sample as .csv for archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(database=dbname, user=dbuser, password=dbpassword, host=host)\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/tais/My_Book_1/MAUPP/Traitement/Ouagadougou/Segmentation_fullAOI_localapproach/Results/CLASSIF/samples'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define the path to the .csv output\n",
    "output=os.path.join(resultfolder,\"all_sample_saraoi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Export as .csv\n",
    "# Query\n",
    "query=\"COPY \"+schema+\".\"+sample_sar+\" TO '\"+output+\"' DELIMITER ',' CSV HEADER\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export training and vaildation sample as .csv for archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define the path to the .csv output\n",
    "sample_training_csv=os.path.join(resultfolder,\"sample_training_saraoi.csv\")\n",
    "sample_test_csv=os.path.join(resultfolder,\"sample_validation_saraoi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Export as .csv\n",
    "# Query\n",
    "query=\"COPY \"+schema+\".\"+sample_training+\" TO '\"+sample_training_csv+\"' DELIMITER ',' CSV HEADER\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Export as .csv\n",
    "# Query\n",
    "query=\"COPY \"+schema+\".\"+sample_test+\" TO '\"+sample_test_csv+\"' DELIMITER ',' CSV HEADER\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test sample for Optical aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create new table with sample which are not outliers and included in optical AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+sample_schema+\".\"+sample_opt)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the 'remove' column with 'yes'\n",
    "query=\"CREATE TABLE \"+sample_schema+\".\"+sample_opt+\" AS(\\\n",
    "SELECT a.* FROM \"+sample_schema+\".\"+samples_labels_ok+\" AS a \\\n",
    "INNER JOIN \"+stat_schema+\".\"+object_stats_optical+\" AS b \\\n",
    "ON a.seg_id=b.cat)\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Delete samples whose class is 12 (building under construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the 'remove' column with 'yes'\n",
    "query=\"DELETE FROM \"+sample_schema+\".\"+sample_opt+\" \\\n",
    "WHERE class_num = '12'\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check if size of sample is sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buildings</td>\n",
       "      <td>11</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swimming pools</td>\n",
       "      <td>13</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asphalt surfaces</td>\n",
       "      <td>14</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown/red bare soil</td>\n",
       "      <td>21</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White/grey bare soil</td>\n",
       "      <td>22</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trees</td>\n",
       "      <td>31</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mixed bare soil/vegetation</td>\n",
       "      <td>32</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dry vegetation</td>\n",
       "      <td>33</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other vegetation</td>\n",
       "      <td>34</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Inland waters</td>\n",
       "      <td>41</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shadows</td>\n",
       "      <td>51</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         class class_num  count\n",
       "0                    Buildings        11    411\n",
       "1               Swimming pools        13    167\n",
       "2             Asphalt surfaces        14    140\n",
       "3          Brown/red bare soil        21    201\n",
       "4         White/grey bare soil        22    171\n",
       "5                        Trees        31    194\n",
       "6   Mixed bare soil/vegetation        32    201\n",
       "7               Dry vegetation        33    178\n",
       "8             Other vegetation        34    314\n",
       "9                Inland waters        41    189\n",
       "10                     Shadows        51    177"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to find the number of row in the sample table\n",
    "query=\"SELECT class, min(class_num) as class_num, count(*) FROM \"+sample_schema+\".\"+sample_opt+\" \\\n",
    "GROUP BY class \\\n",
    "ORDER BY max(class_num) ASC\"\n",
    "# Execute query through panda\n",
    "df_countperclass=pd.read_sql(query, db)\n",
    "# Show dataframe\n",
    "df_countperclass.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtred sample counts 2343 points.\n"
     ]
    }
   ],
   "source": [
    "# Print the total number in sample \n",
    "print \"Filtred sample counts \"+str(sum(df_countperclass['count']))+\" points.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the sample is sufficient\n"
     ]
    }
   ],
   "source": [
    "## Set the minimum size of sample for each class\n",
    "minimumsize=60\n",
    "## Check for each class if the number of sample at least equals the minimum size\n",
    "checkvariable=0\n",
    "for row in range(0,len(df_countperclass.index)):\n",
    "    if int(df_countperclass.loc[row,['count']])<minimumsize:\n",
    "        checkvariable+=1\n",
    "        print \"WARNING: The minimum number of sample is not respected for class '\"+list(df_countperclass.loc[row,['class']])[0]+\"'\"\n",
    "if checkvariable<=0:\n",
    "        print \"The size of the sample is sufficient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vacuum the current Postgresql database\n",
    "vacuum(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random selection of test set and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(database=dbname, user=dbuser, password=dbpassword, host=host)\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 distinct classes are 11,13,14,21,22,31,32,33,34,41,51\n"
     ]
    }
   ],
   "source": [
    "## Create a list with distinct values of class\n",
    "class_column=\"class_num\"\n",
    "query=\"SELECT DISTINCT \"+class_column+\" AS distinct_class from \"+sample_schema+\".\"+sample_opt\n",
    "# Execute query through panda\n",
    "df=pd.read_sql(query, db)\n",
    "# Save estimated number of objects\n",
    "class_list=list(df['distinct_class'])\n",
    "# Print\n",
    "print str(len(class_list))+\" distinct classes are \"+\",\".join([str(y) for y in sorted([int(x) for x in class_list])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 samples will be selected for test\n"
     ]
    }
   ],
   "source": [
    "## Loop on the class_list and save cat_point in a list\n",
    "number_test_perclass=40\n",
    "testsample_list=[]\n",
    "for distinct_class in class_list:\n",
    "    query=\"SELECT cat_point FROM \"+sample_schema+\".\"+sample_opt+\" WHERE random() < 0.5 \\\n",
    "    AND \"+class_column+\"='\"+distinct_class+\"'\\\n",
    "    ORDER BY random() LIMIT 40\"\n",
    "    # Execute query through panda\n",
    "    df=pd.read_sql(query, db)\n",
    "    # Save estimated number of objects\n",
    "    for x in list(df['cat_point']):\n",
    "        testsample_list.append(str(x))\n",
    "    \n",
    "# Print\n",
    "print str(len(testsample_list))+\" samples will be selected for test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+sample_schema+\".\"+sample_opt_test)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Subquery\n",
    "subquery1=\"SELECT * FROM \"+sample_schema+\".\"+sample_opt+\" \\\n",
    "WHERE cat_point IN (\"+\",\".join(testsample_list)+\")\"\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+sample_schema+\".\"+sample_opt_test+\" AS(\"+subquery1+\")\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buildings</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swimming pools</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asphalt surfaces</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown/red bare soil</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White/grey bare soil</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trees</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mixed bare soil/vegetation</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dry vegetation</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other vegetation</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Inland waters</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shadows</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         class class_num  count\n",
       "0                    Buildings        11     40\n",
       "1               Swimming pools        13     40\n",
       "2             Asphalt surfaces        14     40\n",
       "3          Brown/red bare soil        21     40\n",
       "4         White/grey bare soil        22     40\n",
       "5                        Trees        31     40\n",
       "6   Mixed bare soil/vegetation        32     40\n",
       "7               Dry vegetation        33     40\n",
       "8             Other vegetation        34     40\n",
       "9                Inland waters        41     40\n",
       "10                     Shadows        51     40"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to find the number of row in the test samples\n",
    "query=\"SELECT class, min(class_num) as class_num, count(*) FROM \"+sample_schema+\".\"+sample_opt_test+\" \\\n",
    "GROUP BY class \\\n",
    "ORDER BY max(class_num) ASC\"\n",
    "# Execute query through panda\n",
    "df_countperclass=pd.read_sql(query, db)\n",
    "# Show dataframe\n",
    "df_countperclass.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples counts 440 points.\n"
     ]
    }
   ],
   "source": [
    "# Print the total number in sample \n",
    "print \"Test samples counts \"+str(sum(df_countperclass['count']))+\" points.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select training samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+sample_schema+\".\"+sample_opt_training)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Subquery\n",
    "subquery1=\"SELECT * FROM \"+sample_schema+\".\"+sample_opt+\" \\\n",
    "WHERE cat_point NOT IN (\"+\",\".join(testsample_list)+\")\"\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+sample_schema+\".\"+sample_opt_training+\" AS(\"+subquery1+\")\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buildings</td>\n",
       "      <td>11</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swimming pools</td>\n",
       "      <td>13</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asphalt surfaces</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown/red bare soil</td>\n",
       "      <td>21</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White/grey bare soil</td>\n",
       "      <td>22</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trees</td>\n",
       "      <td>31</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mixed bare soil/vegetation</td>\n",
       "      <td>32</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dry vegetation</td>\n",
       "      <td>33</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other vegetation</td>\n",
       "      <td>34</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Inland waters</td>\n",
       "      <td>41</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shadows</td>\n",
       "      <td>51</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         class class_num  count\n",
       "0                    Buildings        11    371\n",
       "1               Swimming pools        13    127\n",
       "2             Asphalt surfaces        14    100\n",
       "3          Brown/red bare soil        21    161\n",
       "4         White/grey bare soil        22    131\n",
       "5                        Trees        31    154\n",
       "6   Mixed bare soil/vegetation        32    161\n",
       "7               Dry vegetation        33    138\n",
       "8             Other vegetation        34    274\n",
       "9                Inland waters        41    149\n",
       "10                     Shadows        51    137"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to find the number of row in the sample table\n",
    "query=\"SELECT class, min(class_num) as class_num, count(*) FROM \"+sample_schema+\".\"+sample_opt_training+\" \\\n",
    "GROUP BY class \\\n",
    "ORDER BY max(class_num) ASC\"\n",
    "# Execute query through panda\n",
    "df_countperclass=pd.read_sql(query, db)\n",
    "# Show dataframe\n",
    "df_countperclass.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples counts 1903 points.\n"
     ]
    }
   ],
   "source": [
    "# Print the total number in sample \n",
    "print \"Training samples counts \"+str(sum(df_countperclass['count']))+\" points.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export full sample as .csv for archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(database=dbname, user=dbuser, password=dbpassword, host=host)\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/tais/My_Book_1/MAUPP/Traitement/Ouagadougou/Segmentation_fullAOI_localapproach/Results/CLASSIF/samples'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define the path to the .csv output\n",
    "output=os.path.join(resultfolder,\"all_sample_optaoi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Export as .csv\n",
    "# Query\n",
    "query=\"COPY \"+sample_schema+\".\"+sample_opt+\" TO '\"+output+\"' DELIMITER ',' CSV HEADER\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export training and vaildation sample as .csv for archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define the path to the .csv output\n",
    "sample_training_csv=os.path.join(resultfolder,\"sample_training_optaoi.csv\")\n",
    "sample_test_csv=os.path.join(resultfolder,\"sample_validation_optaoi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Export as .csv\n",
    "# Query\n",
    "query=\"COPY \"+sample_schema+\".\"+sample_opt_training+\" TO '\"+sample_training_csv+\"' DELIMITER ',' CSV HEADER\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Export as .csv\n",
    "# Query\n",
    "query=\"COPY \"+sample_schema+\".\"+sample_opt_test+\" TO '\"+sample_test_csv+\"' DELIMITER ',' CSV HEADER\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add column with ground truth classes for level 2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to have only one class for bare soils and one class for vegetation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(database=dbname, user=dbuser, password=dbpassword, host=host)\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add column for prediction at level 2b\n",
    "query=\"ALTER TABLE \"+sample_schema+\".\"+sample_opt_test+\" \\\n",
    "ADD COLUMN class_num_b text, \\\n",
    "ADD COLUMN class_b text\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "## Add column for prediction at level 2b\n",
    "query=\"ALTER TABLE \"+sample_schema+\".\"+sample_opt_training+\" \\\n",
    "ADD COLUMN class_num_b text, \\\n",
    "ADD COLUMN class_b text\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update table 'test'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_test+\" SET \\\n",
    "class_num_b = '20' WHERE  class_num IN ('21','22')\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_test+\" SET \\\n",
    "class_num_b = '30' WHERE  class_num IN ('32','33','34')\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_test+\" SET \\\n",
    "class_num_b = class_num WHERE class_num_b IS NULL\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_test+\" SET \\\n",
    "class_b = 'Bare soils' WHERE  class_num_b = '20'\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_test+\" SET \\\n",
    "class_b = 'Low vegetation' WHERE  class_num_b ='30'\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_test+\" SET \\\n",
    "class_b = class WHERE class_b IS NULL\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update table 'training'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_training+\" SET \\\n",
    "class_num_b = '20' WHERE  class_num IN ('21','22')\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_training+\" SET \\\n",
    "class_num_b = '30' WHERE  class_num IN ('32','33','34')\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_training+\" SET \\\n",
    "class_num_b = class_num WHERE class_num_b IS NULL\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_training+\" SET \\\n",
    "class_b = 'Bare soils' WHERE  class_num_b = '20'\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_training+\" SET \\\n",
    "class_b = 'Low vegetation' WHERE  class_num_b ='30'\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_training+\" SET \\\n",
    "class_b = class WHERE class_b IS NULL\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add column with ground truth classes for level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to have only one class for bare soils and one class for vegetation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup a dictionnary with label of level 1 classes\n",
    "level1_dict={}\n",
    "level1_dict['1']=\"Artificial surfaces\"\n",
    "level1_dict['2']=\"Natural material surfaces\"\n",
    "level1_dict['3']=\"Vegetation\"\n",
    "level1_dict['4']=\"Water\"\n",
    "level1_dict['5']=\"Shadows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(database=dbname, user=dbuser, password=dbpassword, host=host)\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add column for prediction at level 2b\n",
    "query=\"ALTER TABLE \"+sample_schema+\".\"+sample_opt_test+\" \\\n",
    "ADD COLUMN class_num_l1 text, \\\n",
    "ADD COLUMN class_l1 text\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "## Add column for prediction at level 2b\n",
    "query=\"ALTER TABLE \"+sample_schema+\".\"+sample_opt_training+\" \\\n",
    "ADD COLUMN class_num_l1 text, \\\n",
    "ADD COLUMN class_l1 text\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update table 'test'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_test+\" SET \\\n",
    "class_num_l1 = class_num::integer/10\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Update column for label of level 2 classes\n",
    "for classes in level1_dict.keys():\n",
    "    query=\"UPDATE \"+sample_schema+\".\"+sample_opt_test+\" \\\n",
    "    SET class_l1 = '\"+level1_dict[classes]+\"' WHERE class_num_l1='\"+str(classes)+\"'\"\n",
    "    # Execute the query \n",
    "    cur.execute(query)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update table 'training'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the value\n",
    "query=\"UPDATE \"+sample_schema+\".\"+sample_opt_training+\" SET \\\n",
    "class_num_l1 = class_num::integer/10\"\n",
    "# Execute the query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Update column for label of level 2 classes\n",
    "for classes in level1_dict.keys():\n",
    "    query=\"UPDATE \"+sample_schema+\".\"+sample_opt_training+\" \\\n",
    "    SET class_l1 = '\"+level1_dict[classes]+\"' WHERE class_num_l1='\"+str(classes)+\"'\"\n",
    "    # Execute the query \n",
    "    cur.execute(query)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<left> <font size=4> <b> End of classification part </b> </font> </left> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The script ends at \"+ time.ctime())\n",
    "print_processing_time(begintime_segmentation_full, \"Entire process has been achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
